{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VGqUQRyzsnzZ"
   },
   "source": [
    "# **1. Cel ćwiczenia**\n",
    "\n",
    "Nieodłącznym elementem każdego systemu radarowego krótkiego zasięgu (Short Range Radar) projektowanego dla przemysłu automotive jest algorytm śledzący. Ma on za zadanie zwrócenie wysokopoziomowej informacji o poruszających się obiektach w otoczeniu czujnika, w postacji trójwymiarowych Bounding Boxów, na podstawie detekcji radarowych.\n",
    "\n",
    "Celem tego ćwiczenia jest zaprojektowanie oraz weryfikacja prostego algorytmu śledzącego opartego na danych z wirtualnego czujnika radarowego wygenerowanych z symulatora CARLA. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SiZgpN4qsnza"
   },
   "source": [
    "# **2. Wymagania wstępne**\n",
    "\n",
    "Do wykonania opisanych ćwiczeń przydatna będzie podstawowa wiedza na temat właściwości czujników radarowych wykorzystywanych w przemyśle samochodowym oraz na temat macierzy transformacji, które będą wykorzystywane do przekształceń pomiędzy różnymi układami referencyjnymi. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzgBcXYNsnzc"
   },
   "source": [
    "# **3. Opis stanowiska laboratoryjnego**\n",
    "\n",
    "Instrukcja do laboratorium jest napisana w formie notebooka jupyterowego, w którym w kilku miejscach będzie wymagane napisanie krótkich fragmentów kodu. Każde jest odpowiednio oznaczone tekstem - **PUT YOUR CODE HERE**. Notebook można uruchomić lokalnie instalując paczkę jupyterlab lub korzystając z przeglądarkowej aplikacji Google Colab. \n",
    "\n",
    "Na potrzeby tego laboratorium w środowisku wirtualnym CARLA przeprowadzono testową symulację, z której wygenerowano 146 ramek danych zawierających: dane z wirtualnych czujników, dane dotyczące pojazdów znajdujących się w testowej symulacji oraz informacje na temat Bounding Boxów wygenerowanych dla tych pojazdów. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V1eH3YOTsnze"
   },
   "source": [
    "## **3.1. CARLA**\n",
    "\n",
    "![carla](https://drive.google.com/uc?id=1QIa0j6oOeYnTyUrj872EmQpPn2EsSLEi)\n",
    "\n",
    "Jest to darmowy symulator stworzony na potrzeby rozwoju i walidacji algorytmów systemów aktywnego bezpieczeństwa i autonomicznej jazdy. Posiada on bardzo rozbudowane środowisko wirtualne zawierające realistycznie odwzorowane modele obiektów. Dodatkowo zaimplementowane są w nim konfigurowalne modele symulacyjne czujników stosowanych w przemyśle automotive, w szczególności:\n",
    "* model kamery\n",
    "* model lidaru\n",
    "* model radaru\n",
    "\n",
    "Dzięki wirtualnym sensorom oraz innym przydatnym funkcjonalościom CARLI (np. sterowanie pogodą czy ilością pojazdów w symulacji) możliwe jest przeprowadzenie wirtualnej walidacji algorytmów, czyli ich testowanie i weryfikacja przeprowadzane w całości w środowisku wirtualnym. Wirtualna walidacja staje się coraz bardziej wykorzystywa w przemyśle automotive, gdyż w środowisku wirtualnym jest możliwe wygenerowanie dowolnego scenariusza drogowego. Dzięki temu rzeczywiste rozwiązanie może być przetestowane w bardzo trudnych sytuacjach często niemożliwych (lub bardzo trudnych i kosztownych) do przeprowadzenia na drodze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "azS4q0r4snzh"
   },
   "source": [
    "## **3.3. Układy współrzędnych**\n",
    "\n",
    "Na potrzeby tego laboratorium definiuje się następujące układy referencyjne:\n",
    "* Globalny układ współrzędnych (**GCS**). Jest to układ współrzędnych, którego początkiem jest punkt $[0, 0, 0]$ symulatora. Wyrażone są w nim pozycje, orientacje oraz prędkości pojazdów.\n",
    "* Układ współrzędnych sensora (**SCS**) - jest to układ współrzędnych zdefiniowany w punkcie, w którym zamocowany jest czujnik. Wyróżniamy dwa układy SCS:\n",
    "    * SCS dla czujnika radarowego (detekcje)\n",
    "    * SCS dla kamery (piksele)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgJ8-cuqsnzi"
   },
   "source": [
    "## **3.4. Dane**\n",
    "\n",
    "Dane dla każdej ramki są zapisane w formie słownika pythonowego. Pola słownika zawierają następujące informacje:\n",
    "* Dane z czujników radarowych, zapisane w \n",
    "    * macierz transformacji z radarowego układu **SCS** do układu **GCS**\n",
    "    * detekcje radarowe dla obu modeli (wbudowanego i wyidealizowanego) zapisane w postaci macierzy typu **numpy.array**, gdzie każdy wiersz to osobna detekcja a każda kolumna to kolejno:\n",
    "        * odległość radialna $r [m]$ \n",
    "        * prędkość radialna detekcji (prędkość względna) $v  [\\frac{m}{s}]$\n",
    "        * kąt azymutu $\\phi [rad]$\n",
    "        * kąt elewacji $\\theta [rad]$\n",
    "       \n",
    "* Dane z kamery:\n",
    "    * macierz transformacji z układu **SCS** kamery do układu **GCS**\n",
    "    * piksele obrazu dla danej ramki\n",
    "* Dane na temat pojazdu hosta:\n",
    "    * ID \n",
    "    * pozycja $p_h = [p_{hx}, p_{hy}, p_{hz}] [m]$ \n",
    "    * prędkość $v_h = [v_{hx}, v_{hy}, v_{hz}] [\\frac{m}{s}]$\n",
    "    * orientacja $\\alpha_h = [roll_{hx}, pitch_{hy}, yaw_{hz}] [rad]$\n",
    "* Lista pythonowa z danymi na temat wszystkich pojazdów (31 pojazdów wliczając pojazd hosta) znajdujących się w wirtualnym scenariuszu:\n",
    "    * ID$^m$ \n",
    "    * pozycja $p_t^m = [p_{tx}^m, p_{ty}^m, p_{tz}^m]$ \n",
    "    * prędkość $v_t^m= [v_{tx}^m, v_{ty}^m, v_{tz}^m] [\\frac{m}{s}]$\n",
    "    * orientacja $\\alpha_t^m = [roll_{tx}^m, pitch_{ty}^m, yaw_{tz}^m] [rad]$, gdzie $m$ to indeks wskazujący na dany pojazd w liście\n",
    "* Lista pythonowa z informacjami na temat Bounding Boxów:\n",
    "    * ID pojazdu, do którego dany Boundng Box jest przypisany\n",
    "    * aktualne współrzędne Bounding Boxa wyrażone w układzie współrzędnych kamery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YiUpAFvYsnzl"
   },
   "source": [
    "# **4. Przebieg ćwiczenia**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YB_4skWTwhlc"
   },
   "source": [
    "## **4.1. Instalacja pakietów**\n",
    "\n",
    "Do przeprowadzenia tego ćwiczenia będą wymagane następujące moduły języka Python:\n",
    "* pickle oraz Path - do wczytania zapisanych danych do słownika Pythonowego\n",
    "* numpy - do operacji macierzowych (transformacje pomiędzy układami współrzędnych)\n",
    "* pygame - do wyświetlania rezultatów (obrazu z kamery, detekcji radarowych, wykrytych Bounding Boxów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nBL4EZ-Wwz1Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/smaket/anaconda3/lib/python3.7/site-packages (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hImWX76Vvc2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib2 in /home/smaket/anaconda3/lib/python3.7/site-packages (2.3.5)\n",
      "Requirement already satisfied: six in /home/smaket/anaconda3/lib/python3.7/site-packages (from pathlib2) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pathlib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O1YGabL_vx_2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /home/smaket/.local/lib/python3.7/site-packages (1.9.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMbc36XXsnzn"
   },
   "source": [
    "## **4.2. Inicjalizacja skryptu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yck-WYcKsnzo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "from pathlib2 import Path\n",
    "import pygame\n",
    "import numpy as np\n",
    "\n",
    "VIEW_WIDTH = 1920 // 2\n",
    "VIEW_HEIGHT = 1080 // 2\n",
    "VIEW_FOV = 90\n",
    "\n",
    "BB_COLOR = (248, 64, 24)\n",
    "DET_COLOR = (255, 255, 0)\n",
    "\n",
    "pygame.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FNE-dX4gsnzv"
   },
   "source": [
    "## **4.3. Wczytanie danych**\n",
    "\n",
    "Teraz należy wczytać pojedynczą ramkę danych. Można także wyświetlić pola składowe słownika Pythonowego:\n",
    "* w przypadku pakietu jupyterlab uruchamianego lokalnie należy umieścić folder **data** w tej samej lokalizacji co notebook\n",
    "* w przypadku korzystania z Google Colab należy:\n",
    "  * w domyślej lokalizacji plików utworzyć folder **data** (opcja New Folder)\n",
    "  * klikając na nowo utworzony folder wybrać opcję **Upload** i załadować z lokalnego dysku wszystkie ramki danych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "47dMJvJ8snzx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['radar', 'camera', 'labels', 'host', 'actors'])\n",
      "dict_keys(['raw_data', 'trans_matrix_radar_to_world'])\n",
      "dict_keys(['carla_model', 'ideal_model'])\n",
      "dict_keys(['raw_data', 'trans_matrix_camera_to_world', 'calibration'])\n",
      "dict_keys(['bounding_box', 'id'])\n",
      "dict_keys(['id', 'position', 'rotation', 'velocity'])\n",
      "31\n",
      "dict_keys(['id', 'position', 'rotation', 'velocity'])\n"
     ]
    }
   ],
   "source": [
    "frame = 101\n",
    "file = Path('data/') / ('frame' + str(frame * 10) + '.dat')\n",
    "if not file.parent.exists():\n",
    "    file.parent.mkdir(parents=True)\n",
    "\n",
    "with open(str(file), 'rb') as in_file:\n",
    "    logging_data = pickle.load(in_file)\n",
    "in_file.close()\n",
    "\n",
    "print(logging_data.keys())\n",
    "print(logging_data['radar'].keys())\n",
    "print(logging_data['radar']['raw_data'].keys())\n",
    "print(logging_data['camera'].keys())\n",
    "print(logging_data['labels'].keys())\n",
    "print(logging_data['host'].keys())\n",
    "print(len(logging_data['actors']))\n",
    "print(logging_data['actors'][0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HzXsHfuysnz1"
   },
   "source": [
    "## **4.4. Widok z kamery**\n",
    "\n",
    "W każdej zapisanej ramce dostępny jest także obraz z kamery, na który w późniejszych etapach zostaną nałożone detekcje radarowe oraz wykryte przez algorytm śledzący Bounding Boxy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M9jljI1bsnz3"
   },
   "outputs": [],
   "source": [
    "image = logging_data['camera']['raw_data']\n",
    "surface = pygame.surfarray.make_surface(image.swapaxes(0, 1))\n",
    "display = pygame.display.set_mode((VIEW_WIDTH, VIEW_HEIGHT), pygame.HWSURFACE | pygame.DOUBLEBUF)\n",
    "display.blit(surface, (0, 0))\n",
    "pygame.display.flip()\n",
    "pygame.event.pump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G0s2RKbPsnz8"
   },
   "source": [
    "## **4.5. Detekcje radarowe**\n",
    "\n",
    "W zapisanych danych dostępne są dwa zestawy detekcji: \n",
    "* z modelu CARLI, którego detekcje zostaną wykorzystane w algorytmie śledzenia\n",
    "* z modelu idealnego służącego jako narzędzie do weryfikacji poprawności przeprowadzonych transformacji układów współrzędnych\n",
    "\n",
    "W obu modelach symulacyjnych dostępny jest także pomiar elewacji. Aktualnie w rzeczywistych czujnikach radarowych pomiar elewacji jest albo niedostępny, albo wyznaczony z bardzo dużym błędem. Warto także dodać, że detekcje radarowe są wyznaczone w konwencji prawoskrętnego układu współrzędnych. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NP0Ip_Yysnz9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43, 4)\n",
      "(103, 4)\n"
     ]
    }
   ],
   "source": [
    "carla_detections = logging_data['radar']['raw_data']['carla_model']\n",
    "print(carla_detections.shape)\n",
    "distance = carla_detections[:, 0]\n",
    "velocity = carla_detections[:, 1]\n",
    "azimuth = carla_detections[:, 2]\n",
    "elevation = carla_detections[:, 3]\n",
    "\n",
    "ideal_detections = logging_data['radar']['raw_data']['ideal_model']\n",
    "print(ideal_detections.shape)\n",
    "distance = ideal_detections[:, 0]\n",
    "velocity = ideal_detections[:, 1]\n",
    "azimuth = ideal_detections[:, 2]\n",
    "elevation = ideal_detections[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zBbu8R6jsn0C"
   },
   "source": [
    "## **4.6. Zadanie nr. 1**\n",
    "\n",
    "Na obrazie z kamery można wyświetlać (po odpowiednich transformacjach) detekcje radarowe. Wyświetlenie detekcji znacznie ułatwi przetestowanie algorytmu śledzącego, gdyż będzie można zobaczyć które obiekty mogły zostać potencjalnie wykryte. \n",
    "\n",
    "Dokonaj transformacji detekcji radarowych do układu **CSC**. Uzyskane rezultaty wyświetl przy użyciu modułu \n",
    "pygame.\n",
    "\n",
    "![model](https://drive.google.com/uc?id=1Mie2rFG-QZNx3P_roA6ipyOrkn6HUyDl)\n",
    "\n",
    "### **Sprawozdanie cz. 1**\n",
    "\n",
    "Wykorzystaj najpierw model idealny do sprawdzenia poprawności transformacji układów współrzędnych. Następnie powtórz tą samą operację dla modelu CARLI. Uzyskane rezultaty wyświetl na obrazie z kamery przy użyciu modułu pygame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1PbG94naMxTg"
   },
   "source": [
    "### Przekształcenie detekcji do układu układu kartezjańskiego\n",
    "\n",
    "Zanim będzie można skorzystać z macierzy transformacji należy przekształcić detekcje radarowe wyrażone we współrzędnych sferycznych do układu kartezjańskiego. \n",
    "\n",
    "Ważna informacją jest tutaj to, że macierze transformacji zostały wygenerowane dla lewoskrętnego układu współrzędnych, gdyż taki właśnie układ jest wykorzystywany w CARLI. Przekształcenie jest proste, gdyż w przypadku współrzędnych (x, y, z) należy tylko zamienić kierunek osi Y. \n",
    "\n",
    "Dodatkowo konieczne jest dodanie czwartego wymiaru do wektora XYZ. Jest to tzw. przekształcenie do współrzędnych jednorodnych. W przypadku przekształceń pomiędzy układami współrzędnych z wykorzystaniem macierzy transformacji czwarta współrzędna ma zawsze wartość 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ixsFvkwxsn0H"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 4)\n"
     ]
    }
   ],
   "source": [
    "# detections = carla_detections\n",
    "detections = ideal_detections\n",
    "print(detections.shape)\n",
    "distance = detections[:, 0]\n",
    "azimuth = detections[:, 2]\n",
    "elevation = detections[:, 3]\n",
    "\n",
    "detections_xyz = np.zeros((detections.shape[0], detections.shape[1]))\n",
    "detections_xyz[:, 0] = distance * np.cos(azimuth) * np.cos(elevation)\n",
    "detections_xyz[:, 1] = -distance * np.sin(azimuth) * np.cos(elevation)\n",
    "detections_xyz[:, 2] = distance * np.sin(elevation)\n",
    "detections_xyz[:, 3] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1l8Wa61Prr6"
   },
   "source": [
    "### Przygotowanie macierzy transformacji\n",
    "\n",
    "Do przekształcenia detekcji radarowych zostaną wykorzystane dwie macierze transformacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lUYbglktRTfd"
   },
   "outputs": [],
   "source": [
    "trans_matrix_radar_to_world = logging_data['radar']['trans_matrix_radar_to_world']\n",
    "trans_matrix_world_to_camera = np.linalg.inv(logging_data['camera']['trans_matrix_camera_to_world'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pXJm4hl0RYJL"
   },
   "source": [
    "### Wyznaczenie złożonej macierzy transformacji\n",
    "\n",
    "Korzystając ze zdefiniowanych wyżej macierzy transformacji należy wyznaczyć jedną macierz reprezentującą złożone przekształcenie. Należy tutaj pamiętać, że transformacje łączy się od prawej do lewej. \n",
    "\n",
    "Wskazówka - wykorzystaj operacje mnożenia macierzowego **dot** dostępną w pakiecie numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kGpj1pIfO8XQ"
   },
   "outputs": [],
   "source": [
    "# PUT YOUR CODE HERE\n",
    "# trans_matrix_radar_to_camera = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XbwKSK_bUqGG"
   },
   "source": [
    "### Przekształcenie punktów z układu współrzędnych radaru do układu współrzędnych kamery\n",
    "\n",
    "Korzystając z wyznaczonej złożonej macierzy transformacji należy przekształcić wektor punktów **detections_xyz** do układu współrzędnych kamery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8cZ2gBMUeKl"
   },
   "outputs": [],
   "source": [
    "# PUT YOUR CODE HERE\n",
    "# detections_camera_xyz = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zYsE8V1GTfOI"
   },
   "source": [
    "### Zrzutowanie punktów XYZ na płaszczyznę kamery\n",
    "\n",
    "Aby możliwe było wyświetlenie współrzędnych XYZ na obrazie kamery należy te współrzędne odpowiednio zrzutować. Na tym etapie pozbywamy się już czwartego wymiaru danych. Był on dodany tylko na potrzeby transformacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hiIHg-XBTgMS"
   },
   "outputs": [],
   "source": [
    "detections_camera_y_minus_z_x = np.concatenate([detections_camera_xyz[1, :], -detections_camera_xyz[2, :],\n",
    "                                                            detections_camera_xyz[0, :]])\n",
    "detections_camera = np.transpose(np.dot(logging_data['camera']['calibration'], detections_camera_y_minus_z_x))\n",
    "detections_camera = np.concatenate([detections_camera[:, 0] / detections_camera[:, 2],\n",
    "                                    detections_camera[:, 1] / detections_camera[:, 2], detections_camera[:, 2]],\n",
    "                                    axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2HiH77duYayI"
   },
   "source": [
    "### Wyświetlenie przekształconych detekcji na obrazie kamery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mk5OpOYYkoR"
   },
   "outputs": [],
   "source": [
    "detection_surface = pygame.Surface((VIEW_WIDTH, VIEW_HEIGHT))\n",
    "detection_surface.set_colorkey((0, 0, 0))\n",
    "for det in detections_camera:\n",
    "  det_tuple = (int(det[0, 0]), int(det[0, 1]))\n",
    "  pygame.draw.circle(detection_surface, DET_COLOR, det_tuple, 2, 0)\n",
    "\n",
    "display.blit(detection_surface, (0, 0))\n",
    "pygame.display.flip()\n",
    "pygame.event.pump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1BrxfOg2Mm1"
   },
   "source": [
    "## **4.7. Bounding Boxy**\n",
    "\n",
    "W zapisanych danych dostępne są Bounding Boxy wygenerowane dla każdego z pojazdów (łącznie z pojazdem hosta)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FYO9n0m74Lpb"
   },
   "source": [
    "### Wyświetlenie Bounding Boxów\n",
    "\n",
    "Jak zostało wspomniane na począ†ku współrzędne Bounding Boxów są już przekształcone do układu współrzędnych kamery (łącznie z rzutowaniem na płaszczyznę kamery), dlatego nie są potrzebne już żadne transformacje.\n",
    "\n",
    "Na tym etapie można wczytywać różne ramki danych (ręcznie lub w pętli), żeby zobaczyć cały przejazd hosta z przeprowadzonej symulacji. Jak można zauważyć wiele spośród wyświetlonych pojazdów (Bounding Boxów) jest nie widoczna przez radar i dlatego nie powinny być dla nich być wyświetlone labelki. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTEi7aka2gqW"
   },
   "outputs": [],
   "source": [
    "bb_surface = pygame.Surface((VIEW_WIDTH, VIEW_HEIGHT))\n",
    "bb_surface.set_colorkey((0, 0, 0))\n",
    "bounding_boxes = logging_data['labels']['bounding_box']\n",
    "for bbox in bounding_boxes:\n",
    "    points = [(int(bbox[i, 0]), int(bbox[i, 1])) for i in range(8)]\n",
    "    # draw lines\n",
    "    # base\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[0], points[1])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[0], points[1])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[1], points[2])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[2], points[3])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[3], points[0])\n",
    "    # top\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[4], points[5])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[5], points[6])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[6], points[7])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[7], points[4])\n",
    "    # base-top\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[0], points[4])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[1], points[5])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[2], points[6])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[3], points[7])\n",
    "display.blit(bb_surface, (0, 0))\n",
    "pygame.display.flip()\n",
    "pygame.event.pump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAF7v74Tsn0L"
   },
   "source": [
    "## **4.8. Rzeczywisty algorytm śledzący**\n",
    "\n",
    "Rzeczywity tracker opiera swoje wyniki tylko na detekcjach radarowych. Estymuje on wielkość i pozycję Bounding Boxa dla **poruszających się** obiektów znajdujących się w polu widzenia radaru. Często wykorzystuje do tego celu różne odmiany filtru Kalmana. \n",
    "\n",
    "W ramach wirtualnej walidacji często na początku projektu przygotowuje się uproszczone modele symulacyjne mające naśladować rzeczywiste algorytmy. Taki uproszczony model musi zwracać dane w takim samym formacie jak rzeczywiste rozwiązanie. Może jednak wyliczyć swoje detekcje korzystając z zupełnie innych informacji. Nie musi także (przynajmniej na początku) zwracać porównywalnych wyników. Chodzi tutaj np. o to, żeby sprawdzić poprawność przepływu danych dla całego systemu aktywnego bezpieczeństwa - od percepcji do sterowania - w środowisku wirtualnym a nie o to, by idealne odwzorować detekcje trackerowe w symulatorze.\n",
    "\n",
    "\n",
    "Zadaniem projektowanego w ramach tego laboratorium rozwiązania będzie przygotowanie uproszczonego algorytmu śledzącego.  \n",
    "\n",
    "W rzeczywistości tracker nie ma informacji o Bounding Boxach pojazdów znajdujących się w jego otoczeniu. W przypadku tego ćwiczenia do projektu trackera mogą zostać wykorzystane wszystkie dostępne w logach dane.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WumbTllKCaD-"
   },
   "source": [
    "## **4.9. Zadanie nr. 2**\n",
    "\n",
    "Przygotuj uproszczony model symulacyjny naśladujący radarowy algorytm śledzący. \n",
    "\n",
    "**Założenia**:\n",
    "* Model powinien korzystać z detekcji radarowych wygenerowanych przez model CARLI\n",
    "* Model powinien zwrócić listę Bounding Boxów dla **poruszających się** obiektów (o niezerowej prędkości względnej) wykrytych przez czujnik radarowy\n",
    "* Wykryte Bounding Boxy należy wyświetlić na obrazie kamery. Pozostałe nie powinny być wyświetlone. \n",
    "\n",
    "\n",
    "**Wskazówki**:\n",
    "* Model radaru powinien dla poruszającego się pojazdu zwrócić kilka detekcji o podobnych do siebie parametrach (prędkości względnej, odległości, kącie). Prędkość względna tych detekcji będzie jednak wyraźnie większa (lub mniejsza) od detekcji pochodzących od obiektów statycznych. Możliwe jest więc pogrupowanie detekcji (przynajmniej w przybliżony sposób) i przypisanie ich do danego obiektu, np. poprzez porównanie średniej odległości dostępnej w detekcji z odległością danego obiektu do samochodu hosta. \n",
    "* Obiekty statyczne także będą mieć niezerową prędkość względną w przypadku, gdy pojazd hosta się porusza.\n",
    "* Zarówno obiekt jak i jego Bounding Box są powiązane ze sobą na podstawie ID, które jest zapisane w obu zbiorach danych. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0cvY2Uqsn0M"
   },
   "outputs": [],
   "source": [
    "visible_bounding_boxes = bounding_box_data['bounding_box']\n",
    "\n",
    "# PUT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tuf8BdHkcBN5"
   },
   "source": [
    "## **4.10. Wyświetlenie rezultatów na obrazie kamery**\n",
    "\n",
    "Wykryte Bounding Boxy należy wyświetlić na obrazie z kamery. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4vCIuTssn0X"
   },
   "outputs": [],
   "source": [
    "bb_surface = pygame.Surface((VIEW_WIDTH, VIEW_HEIGHT))\n",
    "bb_surface.set_colorkey((0, 0, 0))\n",
    "for bbox in visible_bounding_boxes:\n",
    "    points = [(int(bbox[i, 0]), int(bbox[i, 1])) for i in range(8)]\n",
    "    # draw lines\n",
    "    # base\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[0], points[1])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[0], points[1])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[1], points[2])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[2], points[3])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[3], points[0])\n",
    "    # top\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[4], points[5])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[5], points[6])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[6], points[7])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[7], points[4])\n",
    "    # base-top\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[0], points[4])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[1], points[5])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[2], points[6])\n",
    "    pygame.draw.line(bb_surface, BB_COLOR, points[3], points[7])\n",
    "display.blit(bb_surface, (0, 0))\n",
    "pygame.display.flip()\n",
    "pygame.event.pump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q60SCbYwUhWR"
   },
   "source": [
    "## **Destrukcja modułu pygame**\n",
    "\n",
    "Po wykonaniu tej komendy zostanie zamknięte okienko modułu pygame i konieczne będzie ponowne przeprowadzenie jego inicjalizacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LK9gkEBPsn0b"
   },
   "outputs": [],
   "source": [
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y5Lh9Nqosn0f"
   },
   "source": [
    "## **4.11. Sprawozdanie cz. 2**\n",
    "\n",
    "Przetestuj zaprojektowany algorytm dla wszystkich ramek oraz pod kątem różnych scenariuszy. Przygotuj raport końcowy, w którym zamieszczone będą następujące informacje: \n",
    "* ogólny opis i cel zadania\n",
    "* założenia wstępne postawione przed projektowanym algorytmem\n",
    "* schemat blokowy i opis zaimplementowanego rozwiązania:\n",
    "* wyniki oraz wnioski zebrane z testów\n",
    "* zalety i wady przygotowanego algorytmu\n",
    "* potencjalne usprawnienia, które mogłyby być dodane do przyszłych wersji, które uczyniłyby model symulacyjny bardziej rzeczywistym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wa16w9x38FCF"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "AP_LAB17.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
